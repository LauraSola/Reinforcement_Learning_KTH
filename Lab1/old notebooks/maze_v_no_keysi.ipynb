{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright [2024] [KTH Royal Institute of Technology] \n",
    "# Licensed under the Educational Community License, Version 2.0 (ECL-2.0)\n",
    "# This file is part of the Computer Lab 1 for EL2805 - Reinforcement Learning.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython import display\n",
    "import random\n",
    "\n",
    "# Implemented methods\n",
    "methods = ['DynProg', 'ValIter']\n",
    "\n",
    "# Some colours\n",
    "LIGHT_RED    = '#FFC4CC'\n",
    "LIGHT_GREEN  = '#95FD99'\n",
    "BLACK        = '#000000'\n",
    "WHITE        = '#FFFFFF'\n",
    "LIGHT_PURPLE = '#E8D0FF'\n",
    "\n",
    "class Maze:\n",
    "\n",
    "    # Actions\n",
    "    STAY       = 0\n",
    "    MOVE_LEFT  = 1\n",
    "    MOVE_RIGHT = 2\n",
    "    MOVE_UP    = 3\n",
    "    MOVE_DOWN  = 4\n",
    "\n",
    "    # Give names to actions\n",
    "    actions_names = {\n",
    "        STAY: \"stay\",\n",
    "        MOVE_LEFT: \"move left\",\n",
    "        MOVE_RIGHT: \"move right\",\n",
    "        MOVE_UP: \"move up\",\n",
    "        MOVE_DOWN: \"move down\"\n",
    "    }\n",
    "\n",
    "    # Reward values \n",
    "    STEP_REWARD = -100          #TODO\n",
    "    GOAL_REWARD = 100          #TODO\n",
    "    IMPOSSIBLE_REWARD = -100   #TODO\n",
    "    MINOTAUR_REWARD = -100      #TODO\n",
    "\n",
    "    def __init__(self, maze):\n",
    "        \"\"\" Constructor of the environment Maze.\n",
    "        \"\"\"\n",
    "        self.maze                     = maze\n",
    "        self.actions                  = self.__actions()\n",
    "        self.states, self.map         = self.__states()\n",
    "        self.n_actions                = len(self.actions)\n",
    "        self.n_states                 = len(self.states)\n",
    "        self.transition_probabilities = self.__transitions()\n",
    "        self.rewards                  = self.__rewards()\n",
    "\n",
    "    def __actions(self):\n",
    "        actions = dict()\n",
    "        actions[self.STAY]       = (0, 0)\n",
    "        actions[self.MOVE_LEFT]  = (0,-1)\n",
    "        actions[self.MOVE_RIGHT] = (0, 1)\n",
    "        actions[self.MOVE_UP]    = (-1,0)\n",
    "        actions[self.MOVE_DOWN]  = (1,0)\n",
    "        return actions\n",
    "\n",
    "    def __states(self):\n",
    "        \n",
    "        states = dict()\n",
    "        map = dict()\n",
    "        s = 0\n",
    "        for i in range(self.maze.shape[0]):\n",
    "            for j in range(self.maze.shape[1]):\n",
    "                for k in range(self.maze.shape[0]):\n",
    "                    for l in range(self.maze.shape[1]):\n",
    "                        if self.maze[i,j] != 1:\n",
    "                            states[s] = ((i,j), (k,l))\n",
    "                            map[((i,j), (k,l))] = s\n",
    "                            s += 1\n",
    "        \n",
    "        states[s] = 'Eaten'\n",
    "        map['Eaten'] = s\n",
    "        s += 1\n",
    "        \n",
    "        states[s] = 'Win'\n",
    "        map['Win'] = s\n",
    "        \n",
    "        return states, map\n",
    "\n",
    "    def __move(self, state, action):               \n",
    "        \"\"\" Makes a step in the maze, given a current position and an action. \n",
    "            If the action STAY or an inadmissible action is used, the player stays in place.\n",
    "        \n",
    "            :return list of tuples next_state: Possible states ((x,y), (x',y')) on the maze that the system can transition to.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.states[state] == 'Eaten' or self.states[state] == 'Win': # In these states, the game is over\n",
    "            return [self.states[state]]\n",
    "        \n",
    "        else: # Compute the future possible positions given current (state, action)\n",
    "            row_player = self.states[state][0][0] + self.actions[action][0] # Row of the player's next position \n",
    "            col_player = self.states[state][0][1] + self.actions[action][1] # Column of the player's next position \n",
    "            \n",
    "            # Is the player getting out of the limits of the maze or hitting a wall?\n",
    "            impossible_action_player = (row_player == -1 or row_player == self.maze.shape[0] or \\\n",
    "                                         col_player == -1 or col_player == self.maze.shape[1] or \\\n",
    "                                         self.maze[row_player, col_player] == 1 ) #TODO\n",
    "            \n",
    "            actions_minotaur = [[0, -1], [0, 1], [-1, 0], [1, 0]] # Possible moves for the Minotaur\n",
    "            rows_minotaur, cols_minotaur = [], []\n",
    "            for i in range(len(actions_minotaur)):\n",
    "                # Is the minotaur getting out of the limits of the maze?\n",
    "                impossible_action_minotaur = (self.states[state][1][0] + actions_minotaur[i][0] == -1) or \\\n",
    "                                             (self.states[state][1][0] + actions_minotaur[i][0] == self.maze.shape[0]) or \\\n",
    "                                             (self.states[state][1][1] + actions_minotaur[i][1] == -1) or \\\n",
    "                                             (self.states[state][1][1] + actions_minotaur[i][1] == self.maze.shape[1])\n",
    "            \n",
    "                if not impossible_action_minotaur:\n",
    "                    rows_minotaur.append(self.states[state][1][0] + actions_minotaur[i][0])\n",
    "                    cols_minotaur.append(self.states[state][1][1] + actions_minotaur[i][1])  \n",
    "          \n",
    "\n",
    "            # Based on the impossiblity check return the next possible states.\n",
    "            if impossible_action_player: # The action is not possible, so the player remains in place\n",
    "                states = []\n",
    "                for i in range(len(rows_minotaur)):\n",
    "                    \n",
    "                    if (self.states[state][0][0] == rows_minotaur[i] and self.states[state][0][1] == cols_minotaur[i]): # TODO: We met the minotaur\n",
    "                        states.append('Eaten')\n",
    "                    \n",
    "                    elif (self.maze[self.states[state][0][0], self.states[state][0][1]] == 2 ): # TODO: We are at the exit state, without meeting the minotaur\n",
    "                        states.append('Win')\n",
    "                \n",
    "                    else: # The player remains in place, the minotaur moves randomly\n",
    "                        states.append(((self.states[state][0][0], self.states[state][0][1]), (rows_minotaur[i], cols_minotaur[i])))\n",
    "                \n",
    "                return states\n",
    "          \n",
    "            else: # The action is possible, the player and the minotaur both move\n",
    "                states = []\n",
    "                for i in range(len(rows_minotaur)):\n",
    "                \n",
    "                    if (row_player == rows_minotaur[i] and col_player == cols_minotaur[i]): # TODO: We met the minotaur\n",
    "                        states.append('Eaten')\n",
    "                    \n",
    "                    elif self.maze[row_player, col_player] == 2: # TODO:We are at the exit state, without meeting the minotaur\n",
    "                        states.append('Win')\n",
    "                    \n",
    "                    else: # The player moves, the minotaur moves randomly\n",
    "                        states.append(((row_player, col_player), (rows_minotaur[i], cols_minotaur[i])))\n",
    "              \n",
    "                return states\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def __transitions(self):\n",
    "        \"\"\" Computes the transition probabilities for every state action pair.\n",
    "            :return numpy.tensor transition probabilities: tensor of transition\n",
    "            probabilities of dimension S*S*A\n",
    "        \"\"\"\n",
    "        # Initialize the transition probailities tensor (S,S,A)\n",
    "        dimensions = (self.n_states,self.n_states,self.n_actions)\n",
    "        transition_probabilities = np.zeros(dimensions)\n",
    "\n",
    "        # TODO: Compute the transition probabilities.\n",
    "  \n",
    "        for s in range(self.n_states):\n",
    "                for a in range(self.n_actions):\n",
    "                    next_possible_states = self.__move(s,a)\n",
    "                    prob_next = 1.0/len(next_possible_states)\n",
    "\n",
    "                    for t in next_possible_states:\n",
    "                        transition_probabilities[self.map[t],s,a] = prob_next\n",
    "    \n",
    "        return transition_probabilities\n",
    "\n",
    "\n",
    "\n",
    "    def __rewards(self):\n",
    "        \n",
    "        \"\"\" Computes the rewards for every state action pair \"\"\"\n",
    "\n",
    "        rewards = np.zeros((self.n_states, self.n_actions))\n",
    "        \n",
    "        for s in range(self.n_states):\n",
    "            for a in range(self.n_actions):\n",
    "                \n",
    "                if self.states[s] == 'Eaten': # The player has been eaten\n",
    "                    rewards[s, a] = self.MINOTAUR_REWARD\n",
    "                \n",
    "                elif self.states[s] == 'Win': # The player has won\n",
    "                    rewards[s, a] = self.GOAL_REWARD\n",
    "                \n",
    "                else:                \n",
    "                    next_states = self.__move(s,a)\n",
    "                    next_s = next_states[0] # The reward does not depend on the next position of the minotaur, we just consider the first one\n",
    "                    \n",
    "                    if self.states[s][0] == next_s[0] and a != self.STAY: # The player hits a wall\n",
    "                        rewards[s, a] = self.IMPOSSIBLE_REWARD\n",
    "                    \n",
    "                    else: # Regular move\n",
    "                        rewards[s, a] = self.STEP_REWARD\n",
    "\n",
    "        return rewards\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def simulate(self, start, policy, method):\n",
    "        \n",
    "        if method not in methods:\n",
    "            error = 'ERROR: the argument method must be in {}'.format(methods)\n",
    "            raise NameError(error)\n",
    "\n",
    "        path = list()\n",
    "        \n",
    "        if method == 'DynProg':\n",
    "            horizon = policy.shape[1] # Deduce the horizon from the policy shape\n",
    "            t = 0 # Initialize current time\n",
    "            s = self.map[start] # Initialize current state \n",
    "            path.append(start) # Add the starting position in the maze to the path\n",
    "            \n",
    "            while t < horizon - 1:\n",
    "                a = int(policy[s, t]) # Move to next state given the policy and the current state       \n",
    "                next_states = self.__move(s, a) # Move to next state given the policy and the current state\n",
    "                map_next_states = [self.map[state] for state in next_states] # Map the next states\n",
    "                next_s = np.random.choice(map_next_states, p=self.transition_probabilities[map_next_states, s, a])  # Choose the next state given the transition probabilities\n",
    "                path.append(self.states[next_s]) # Add the next state to the path\n",
    "                t +=1 # Update time and state for next iteration\n",
    "                s = next_s\n",
    "                \n",
    "        if method == 'ValIter': \n",
    "            t = 1 # Initialize current state, next state and time\n",
    "            s = self.map[start]\n",
    "            path.append(start) # Add the starting position in the maze to the path\n",
    "            next_states = self.__move(s, policy[s]) # Move to next state given the policy and the current state\n",
    "            map_next_states = [self.map[state] for state in next_states] # Map the next states\n",
    "            next_s = np.random.choice(map_next_states, p=self.transition_probabilities[map_next_states, s, policy[s]])  # Choose the next state given the transition probabilities\n",
    "            path.append(self.states[next_s]) # Add the next state to the path\n",
    "            \n",
    "            # horizon geometric mean 30\n",
    "            horizon = np.random.geometric(1/30) # Sample the horizon from a geometric distribution with mean 30\n",
    "            \n",
    "            # Loop while state is not the goal state\n",
    "            while s != next_s and t <= horizon:\n",
    "                s = next_s # Update state\n",
    "                next_states = self.__move(s, policy[s]) # Move to next state given the policy and the current state\n",
    "                map_next_states = [self.map[state] for state in next_states] # Map the next states\n",
    "                next_s = np.random.choice(map_next_states, p=self.transition_probabilities[map_next_states, s, policy[s]])  # Choose the next state given the transition probabilities\n",
    "                path.append(self.states[next_s]) # Add the next state to the path\n",
    "                t += 1 # Update time for next iteration\n",
    "        \n",
    "        return [path, horizon] # Return the horizon as well, to plot the histograms for the VI\n",
    "\n",
    "\n",
    "\n",
    "    def show(self):\n",
    "        print('The states are :')\n",
    "        print(self.states)\n",
    "        print('The actions are:')\n",
    "        print(self.actions)\n",
    "        print('The mapping of the states:')\n",
    "        print(self.map)\n",
    "        print('The rewards:')\n",
    "        print(self.rewards)\n",
    "\n",
    "\n",
    "\n",
    "def dynamic_programming(env, horizon):\n",
    "    \"\"\" Solves the shortest path problem using dynamic programming\n",
    "        :input Maze env           : The maze environment in which we seek to\n",
    "                                    find the shortest path.\n",
    "        :input int horizon        : The time T up to which we solve the problem.\n",
    "        :return numpy.array V     : Optimal values for every state at every\n",
    "                                    time, dimension S*T\n",
    "        :return numpy.array policy: Optimal time-varying policy at every state,\n",
    "                                    dimension S*T\n",
    "    \"\"\"\n",
    "    #TODO\n",
    "\n",
    "    ### MDP\n",
    "    P         = env.transition_probabilities\n",
    "    r         = env.rewards\n",
    "    n_states  = env.n_states\n",
    "    n_actions = env.n_actions\n",
    "    T         = horizon\n",
    "\n",
    "    ### objectives to compute\n",
    "    V = np.zeros((env.n_states, horizon+1))\n",
    "    policy = np.zeros((env.n_states, horizon+1))\n",
    "\n",
    "    #initialization\n",
    "    V[env.map['Win'], -1] = 1\n",
    "    V[env.map['Eaten'], -1] = -100\n",
    "\n",
    "    for t in range(T-1, -1, -1):\n",
    "        Q = np.zeros((n_states, n_actions))\n",
    "        for s in range(n_states):\n",
    "            for a in range(n_actions):\n",
    "                Q[s,a] = r[s,a]\n",
    "                for j in range(env.n_states):\n",
    "                    Q[s,a] += P[j,s,a]*V[j,t+1]\n",
    "    \n",
    "            V[s,t] = np.max(Q[s, :])\n",
    "            policy[s,t] = np.argmax(Q[s,:])\n",
    "\n",
    "    return V, policy\n",
    "\n",
    "def value_iteration(env, gamma, epsilon):\n",
    "    \"\"\" Solves the shortest path problem using value iteration\n",
    "        :input Maze env           : The maze environment in which we seek to\n",
    "                                    find the shortest path.\n",
    "        :input float gamma        : The discount factor.\n",
    "        :input float epsilon      : accuracy of the value iteration procedure.\n",
    "        :return numpy.array V     : Optimal values for every state at every\n",
    "                                    time, dimension S*T\n",
    "        :return numpy.array policy: Optimal time-varying policy at every state,\n",
    "                                    dimension S*T\n",
    "    \"\"\"\n",
    "\n",
    "    P = env.transition_probabilities  # Shape: (n_states, n_states, n_actions)\n",
    "    r = env.rewards                   # Shape: (n_states, n_actions)\n",
    "    n_states = env.n_states\n",
    "    n_actions = env.n_actions\n",
    "\n",
    "    V = np.zeros(n_states)  # Initialize value function\n",
    "    policy = np.zeros(n_states, dtype=int)  # Initialize policy\n",
    "\n",
    "    tolerance_thr = epsilon * (1 - gamma) / gamma\n",
    "    delta = tolerance_thr + 1  # Force at least one iteration\n",
    "\n",
    "    while delta > tolerance_thr:\n",
    "        Q = np.zeros((n_states, n_actions))  # Store Q-values for all states and actions\n",
    "\n",
    "        # Compute Q-values for each action in each state\n",
    "        for s in range(n_states):\n",
    "            for a in range(n_actions):\n",
    "                Q[s, a] = r[s, a] + gamma * np.dot(P[:, s, a], V)\n",
    "\n",
    "        # Get the best value and action for each state\n",
    "        V_next = np.max(Q, axis=1)\n",
    "\n",
    "        # Update convergence criterion\n",
    "        delta = np.max(np.abs(V_next - V))\n",
    "        V = V_next\n",
    "    \n",
    "    policy = np.argmax(Q, axis=1)\n",
    "\n",
    "    return V, policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate_solution(maze, path):\n",
    "\n",
    "    # Map a color to each cell in the maze\n",
    "    col_map = {0: WHITE, 1: BLACK, 2: LIGHT_GREEN, -1: LIGHT_RED, -2: LIGHT_PURPLE}\n",
    "    \n",
    "    rows, cols = maze.shape # Size of the maze\n",
    "    fig = plt.figure(1, figsize=(cols, rows)) # Create figure of the size of the maze\n",
    "\n",
    "    # Remove the axis ticks and add title\n",
    "    ax = plt.gca()\n",
    "    ax.set_title('Policy simulation')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # Give a color to each cell\n",
    "    colored_maze = [[col_map[maze[j, i]] for i in range(cols)] for j in range(rows)]\n",
    "\n",
    "    # Create a table to color\n",
    "    grid = plt.table(\n",
    "        cellText = None, \n",
    "        cellColours = colored_maze, \n",
    "        cellLoc = 'center', \n",
    "        loc = (0,0), \n",
    "        edges = 'closed'\n",
    "    )\n",
    "    \n",
    "    # Modify the height and width of the cells in the table\n",
    "    tc = grid.properties()['children']\n",
    "    for cell in tc:\n",
    "        cell.set_height(1.0/rows)\n",
    "        cell.set_width(1.0/cols)\n",
    "\n",
    "    for i in range(0, len(path)):\n",
    "        if path[i-1] != 'Eaten' and path[i-1] != 'Win':\n",
    "            grid.get_celld()[(path[i-1][0])].set_facecolor(col_map[maze[path[i-1][0]]])\n",
    "            grid.get_celld()[(path[i-1][1])].set_facecolor(col_map[maze[path[i-1][1]]])\n",
    "        if path[i] != 'Eaten' and path[i] != 'Win':\n",
    "            grid.get_celld()[(path[i][0])].set_facecolor(col_map[-2]) # Position of the player\n",
    "            grid.get_celld()[(path[i][1])].set_facecolor(col_map[-1]) # Position of the minotaur\n",
    "        display.display(fig)\n",
    "        time.sleep(1)\n",
    "        display.clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Description of the maze as a numpy array\n",
    "    maze = np.array([\n",
    "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 1, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 1, 0, 0, 1, 1, 1],\n",
    "        [0, 0, 1, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 1, 1, 1, 1, 1, 1, 0],\n",
    "        [0, 0, 0, 0, 1, 2, 0, 0]])\n",
    "    # With the convention 0 = empty cell, 1 = obstacle, 2 = exit of the Maze\n",
    "    \n",
    "    env = Maze(maze) # Create an environment maze\n",
    "    horizon = 20       # TODO: Finite horizon\n",
    "    gamma = 29/30\n",
    "    epsilon = 0.0000001 #10^-4\n",
    "\n",
    "    # Solve the MDP problem with dynamic programming\n",
    "    V, policy = value_iteration(env, gamma, epsilon)\n",
    "\n",
    "    # Simulate the shortest path starting from position A\n",
    "    method = 'ValIter'\n",
    "    start  = ((0,0), (6,5)) # Initial state\n",
    "    path = env.simulate(start, policy, method)[0]\n",
    "\n",
    "    animate_solution(maze, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 0), (6, 5)),\n",
       " ((0, 1), (6, 4)),\n",
       " ((1, 1), (5, 4)),\n",
       " ((2, 1), (4, 4)),\n",
       " ((3, 1), (4, 5)),\n",
       " ((4, 1), (3, 5)),\n",
       " ((4, 2), (2, 5)),\n",
       " ((4, 3), (1, 5)),\n",
       " ((4, 4), (0, 5)),\n",
       " ((4, 5), (0, 4)),\n",
       " ((4, 6), (0, 3)),\n",
       " ((4, 7), (1, 3)),\n",
       " ((5, 7), (1, 4)),\n",
       " ((6, 7), (0, 4)),\n",
       " ((6, 6), (0, 3)),\n",
       " 'Win',\n",
       " 'Win']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = env.simulate(start, policy, method)[0]\n",
    "\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6248\n",
      "6248\n"
     ]
    }
   ],
   "source": [
    "n_alive = 0\n",
    "n_horizon_more_15 = 0\n",
    "for sim in range(10000):\n",
    "    # Simulate the shortest path starting from position A\n",
    "    method = 'ValIter'\n",
    "    start  = ((0,0), (6,5)) # Initial state\n",
    "    sim = env.simulate(start, policy, method)\n",
    "    if sim[1]>=15:\n",
    "        n_horizon_more_15+=1\n",
    "    else:\n",
    "        #animate_solution(maze, path)\n",
    "        continue\n",
    "\n",
    "    if sim[0][-1] == 'Win':\n",
    "        n_alive+=1\n",
    "\n",
    "print(n_alive)\n",
    "print(n_horizon_more_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 2, 4}\n"
     ]
    }
   ],
   "source": [
    "unique_actions = set()  # Use this instead of naming it 'set'\n",
    "\n",
    "# Iterate over each state in the environment\n",
    "for state in range(env.n_states):\n",
    "    # Check if the condition on env.states is satisfied\n",
    "    if env.states[state][0][0] == 0 and env.states[state][0][1] == 0:\n",
    "        # Add the corresponding policy action to the set\n",
    "        unique_actions.add(policy[state])\n",
    "\n",
    "print(unique_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "animate_solution(maze, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 0), (6, 5)),\n",
       " ((0, 1), (5, 5)),\n",
       " ((1, 1), (6, 5)),\n",
       " ((2, 1), (5, 5)),\n",
       " ((3, 1), (5, 6)),\n",
       " ((4, 1), (5, 5)),\n",
       " ((4, 2), (6, 5)),\n",
       " ((4, 3), (5, 5)),\n",
       " ((4, 4), (4, 5)),\n",
       " ((4, 5), (4, 4)),\n",
       " ((4, 6), (4, 3)),\n",
       " ((4, 7), (3, 3)),\n",
       " ((5, 7), (4, 3)),\n",
       " ((6, 7), (3, 3)),\n",
       " ((6, 6), (4, 3)),\n",
       " 'Win',\n",
       " 'Win']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy[2158]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 0), (6, 5)),\n",
       " ((0, 1), (6, 4)),\n",
       " ((1, 1), (6, 3)),\n",
       " ((2, 1), (6, 4)),\n",
       " ((3, 1), (6, 3)),\n",
       " ((4, 1), (6, 4)),\n",
       " ((4, 2), (6, 3)),\n",
       " ((4, 3), (6, 2)),\n",
       " ((4, 4), (6, 3)),\n",
       " ((4, 5), (6, 4)),\n",
       " ((4, 6), (6, 5)),\n",
       " ((4, 7), (5, 5)),\n",
       " ((5, 7), (4, 5)),\n",
       " ((6, 7), (3, 5)),\n",
       " ((6, 6), (3, 6)),\n",
       " ((6, 6), (3, 7)),\n",
       " 'Win',\n",
       " 'Win']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = env.simulate(start, policy, method)[0]\n",
    "\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2158"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.map[(6, 6), (3, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy[2158]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "animate_solution(maze, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 0), (6, 5)),\n",
       " ((0, 1), (5, 5)),\n",
       " ((1, 1), (4, 5)),\n",
       " ((2, 1), (5, 5)),\n",
       " ((3, 1), (5, 6)),\n",
       " ((4, 1), (4, 6)),\n",
       " ((4, 2), (3, 6)),\n",
       " ((4, 3), (3, 7)),\n",
       " ((4, 4), (3, 6)),\n",
       " ((4, 5), (3, 7)),\n",
       " ((4, 6), (3, 6)),\n",
       " ((4, 7), (2, 6)),\n",
       " ((5, 7), (2, 5)),\n",
       " ((6, 7), (2, 6)),\n",
       " ((6, 6), (1, 6)),\n",
       " ((6, 6), (1, 7)),\n",
       " ((6, 6), (0, 7)),\n",
       " 'Win',\n",
       " 'Win']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = env.simulate(start, policy, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "animate_solution(maze, path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = Maze(maze) # Create an environment maze\n",
    "\n",
    "# Simulate the shortest path starting from position A\n",
    "method = 'ValIter'\n",
    "start  = ((0,0), (6,5)) # Initial state\n",
    "path = env.simulate(start, policy, method)[0]\n",
    "\n",
    "animate_solution(maze, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 0), (6, 5)),\n",
       " ((0, 1), (6, 4)),\n",
       " ((1, 1), (5, 4)),\n",
       " ((2, 1), (4, 4)),\n",
       " ((3, 1), (3, 4)),\n",
       " ((4, 1), (2, 4)),\n",
       " ((4, 2), (2, 5)),\n",
       " ((4, 3), (3, 5)),\n",
       " ((4, 4), (4, 5)),\n",
       " ((4, 5), (4, 4)),\n",
       " ((4, 6), (4, 3)),\n",
       " ((4, 7), (4, 4)),\n",
       " ((5, 7), (4, 3)),\n",
       " ((6, 7), (4, 4)),\n",
       " ((6, 6), (5, 4)),\n",
       " ((6, 6), (5, 5)),\n",
       " ((6, 6), (6, 5)),\n",
       " 'Win',\n",
       " 'Win']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
